{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/7e/184d995d711e3401722769cd6982b46d42aee14a82ba54a3a79425f939c9/matplotlib-3.0.3-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (14.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 14.3MB 1.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib) (2.6.1)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl (62kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 7.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib) (1.16.3)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/5d/d1726d2a2fd471a69ef5014ca42812e1ccb8a13085c42bfcb238a5611f39/kiwisolver-1.1.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (113kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 8.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (28.8.0)\n",
      "Installing collected packages: pyparsing, cycler, kiwisolver, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.0.3 pyparsing-2.4.0\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[3],cmap=plt.cm.binary)\n",
    "\n",
    "plt.show()\n",
    "print(y_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.2249006  0.51284814 0.57894171 0.58191321 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.18162512\n",
      "  0.44254634 0.508794   0.57440099 0.57267649 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.2402749\n",
      "  0.45524234 0.508794   0.57440099 0.57267649 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.12827814 0.44649508\n",
      "  0.45524234 0.42771129 0.07038115 0.07389374 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.11264691 0.43010907 0.47487401\n",
      "  0.45524234 0.19054437 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.29100452 0.47727015 0.47865786\n",
      "  0.34279204 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.03507342 0.47499447 0.47349726 0.44460315\n",
      "  0.11970516 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05777143 0.35950254 0.47499447 0.47349726 0.23838297\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18775714 0.4401714  0.47499447 0.34710556 0.02837892\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12554956 0.43328571 0.4401714  0.36234756 0.0433882  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04673221\n",
      "  0.39705049 0.45675535 0.44367875 0.29851431 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.22051763\n",
      "  0.39391175 0.45314464 0.4401714  0.07322049 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.07218821 0.32274434\n",
      "  0.39391175 0.45314464 0.3016314  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.3519175  0.36655579\n",
      "  0.39391175 0.35384999 0.02104405 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.380492   0.36655579\n",
      "  0.39391175 0.16067678 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.32420905 0.38349984 0.36947656\n",
      "  0.39705049 0.05596607 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.45617155 0.46490355 0.380492   0.36071427\n",
      "  0.21971173 0.01444286 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.60822874 0.51180171 0.380492   0.32128396\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.60822874 0.51180171 0.380492   0.32128396\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.22808578 0.39353678 0.380492   0.32128396\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "print(x_train[3])\n",
    "\n",
    "plt.imshow(x_train[3],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A sequential model is what you're going to use most of the time. It just means things are going to go in direct order. A feed forward model. No going backwards.\n",
    "\n",
    "Now, we'll pop in layers. Recall our neural network image? Was the input layer flat, or was it multi-dimensional? It was flat. So, we need to take this 28x28 image, and make it a flat 1x784. There are many ways for us to do this, but keras has a Flatten layer built just for us, so we'll use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we want our hidden layers. We're going to go with the simplest neural network layer, which is just a Dense layer. \n",
    "This refers to the fact that it's a densely-connected layer, meaning it's \"fully connected,\" where each node connects to each prior and subsequent node. Just like our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This layer has 128 units. The activation function is relu, short for rectified linear. Currently, relu is the activation function you should just default to. There are many more to test for sure, but, if you don't know what to use, use relu to start.\n",
    "This is our final layer. It has 10 nodes. 1 node per possible number prediction. In this case, our activation function is a softmax function, since we're really actually looking for something more like a probability distribution of which of the possible prediction options this thing we're passing features through of is. Great, our model is done.\n",
    "Now we need to \"compile\" the model. This is where we pass the settings for actually optimizing/training the model we've defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember why we picked relu as an activation function? Same thing is true for the Adam optimizer. It's just a great default to start with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model Now Fit\n",
    "A neural network doesn't actually attempt to maximize accuracy. It attempts to minimize loss. Again, there are many choices, but some form of categorical crossentropy is a good start for a classification task like this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2659 - acc: 0.9228\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1084 - acc: 0.9670\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0721 - acc: 0.9771\n",
      "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0874 - acc: 0.9735\n",
      "0.0873668703502044\n",
      "0.9735\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=3)\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)  # evaluate the out of sample data with model\n",
    "print(val_loss)  # model's loss (error)\n",
    "print(val_acc)  # model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n",
      "[[6.1808532e-09 1.9234882e-08 1.7528541e-07 ... 9.9999440e-01\n",
      "  4.1788013e-09 2.8753220e-06]\n",
      " [3.0087077e-10 2.2670458e-04 9.9976641e-01 ... 7.9995868e-09\n",
      "  1.3516745e-07 6.8420812e-13]\n",
      " [8.6087304e-08 9.9979442e-01 1.8711591e-05 ... 1.6518890e-05\n",
      "  1.4055030e-04 2.1966221e-06]\n",
      " ...\n",
      " [2.6634264e-10 1.3386773e-05 4.2536804e-08 ... 6.8762056e-05\n",
      "  1.4500791e-05 5.0337080e-06]\n",
      " [1.4355449e-05 4.6657101e-07 2.3978959e-07 ... 1.2049119e-06\n",
      "  7.7280565e-03 2.9087419e-08]\n",
      " [7.0761484e-07 2.0913099e-06 3.6657732e-06 ... 1.4932031e-09\n",
      "  3.9041848e-07 2.8947906e-07]]\n"
     ]
    }
   ],
   "source": [
    "model.save('epic_num_reader.model')\n",
    "new_model = tf.keras.models.load_model('epic_num_reader.model')\n",
    "predictions = new_model.predict(x_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.argmax(predictions[5]))\n",
    "plt.imshow(x_test[5],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
