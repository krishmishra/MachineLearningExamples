{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nuberclassification_linearregration_v2_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishmishra/MachineLearningExamples/blob/master/Nuberclassification_linearregration_v2_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUVcLCfA4tQ9",
        "colab_type": "code",
        "outputId": "754ed43b-f9ab-4364-a2d1-6e9938cb1bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF8ecSLl4tRB",
        "colab_type": "code",
        "outputId": "9b4a357e-23ad-4732-a2f8-39007afaefb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "print(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "587-Gacr4tRH",
        "colab_type": "code",
        "outputId": "b2920fce-b7c7-446d-8ae3-aab41f7821ab",
        "colab": {}
      },
      "source": [
        "pip install --upgrade matplotlib"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting matplotlib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/7e/184d995d711e3401722769cd6982b46d42aee14a82ba54a3a79425f939c9/matplotlib-3.0.3-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (14.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 14.3MB 1.0MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib) (2.6.1)\n",
            "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl (62kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 7.2MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib) (1.16.3)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/5d/d1726d2a2fd471a69ef5014ca42812e1ccb8a13085c42bfcb238a5611f39/kiwisolver-1.1.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (113kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 8.7MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.10.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (28.8.0)\n",
            "Installing collected packages: pyparsing, cycler, kiwisolver, matplotlib\n",
            "Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.0.3 pyparsing-2.4.0\n",
            "\u001b[33mYou are using pip version 18.1, however version 19.1 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytCa1Eq94tRL",
        "colab_type": "code",
        "outputId": "801d21d7-d8da-472d-9fae-48b80e6bd05d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[3],cmap=plt.cm.binary)\n",
        "\n",
        "plt.show()\n",
        "print(y_train[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEdhFE7m4tRO",
        "colab_type": "code",
        "outputId": "d2532fd7-0d20-46f8-8ec4-bafdfd255d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2649
        }
      },
      "source": [
        "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
        "print(x_train[3])\n",
        "\n",
        "plt.imshow(x_train[3],cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.2249006  0.51284814 0.57894171 0.58191321 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.18162512\n",
            "  0.44254634 0.508794   0.57440099 0.57267649 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.2402749\n",
            "  0.45524234 0.508794   0.57440099 0.57267649 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.12827814 0.44649508\n",
            "  0.45524234 0.42771129 0.07038115 0.07389374 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.11264691 0.43010907 0.47487401\n",
            "  0.45524234 0.19054437 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.29100452 0.47727015 0.47865786\n",
            "  0.34279204 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.03507342 0.47499447 0.47349726 0.44460315\n",
            "  0.11970516 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.05777143 0.35950254 0.47499447 0.47349726 0.23838297\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.18775714 0.4401714  0.47499447 0.34710556 0.02837892\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.12554956 0.43328571 0.4401714  0.36234756 0.0433882  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.04673221\n",
            "  0.39705049 0.45675535 0.44367875 0.29851431 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.22051763\n",
            "  0.39391175 0.45314464 0.4401714  0.07322049 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.07218821 0.32274434\n",
            "  0.39391175 0.45314464 0.3016314  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.3519175  0.36655579\n",
            "  0.39391175 0.35384999 0.02104405 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.380492   0.36655579\n",
            "  0.39391175 0.16067678 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.32420905 0.38349984 0.36947656\n",
            "  0.39705049 0.05596607 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.45617155 0.46490355 0.380492   0.36071427\n",
            "  0.21971173 0.01444286 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.60822874 0.51180171 0.380492   0.32128396\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.60822874 0.51180171 0.380492   0.32128396\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.22808578 0.39353678 0.380492   0.32128396\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXSHKwwA4tRQ",
        "colab_type": "text"
      },
      "source": [
        "# A sequential model is what you're going to use most of the time. It just means things are going to go in direct order. A feed forward model. No going backwards.\n",
        "\n",
        "Now, we'll pop in layers. Recall our neural network image? Was the input layer flat, or was it multi-dimensional? It was flat. So, we need to take this 28x28 image, and make it a flat 1x784. There are many ways for us to do this, but keras has a Flatten layer built just for us, so we'll use that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exZQ4P6j4tRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3572Q0-b4tRT",
        "colab_type": "text"
      },
      "source": [
        "# we want our hidden layers. We're going to go with the simplest neural network layer, which is just a Dense layer. \n",
        "This refers to the fact that it's a densely-connected layer, meaning it's \"fully connected,\" where each node connects to each prior and subsequent node. Just like our image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKHFH8Eb4tRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSQrTWNA4tRW",
        "colab_type": "text"
      },
      "source": [
        "# This layer has 128 units. The activation function is relu, short for rectified linear. Currently, relu is the activation function you should just default to. There are many more to test for sure, but, if you don't know what to use, use relu to start.\n",
        "This is our final layer. It has 10 nodes. 1 node per possible number prediction. In this case, our activation function is a softmax function, since we're really actually looking for something more like a probability distribution of which of the possible prediction options this thing we're passing features through of is. Great, our model is done.\n",
        "Now we need to \"compile\" the model. This is where we pass the settings for actually optimizing/training the model we've defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9ua3dc_4tRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcjRDq8u4tRZ",
        "colab_type": "text"
      },
      "source": [
        "# Remember why we picked relu as an activation function? Same thing is true for the Adam optimizer. It's just a great default to start with.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K80vriwC4tRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8ZzzUIJ4tRb",
        "colab_type": "text"
      },
      "source": [
        "# Train the model Now Fit\n",
        "A neural network doesn't actually attempt to maximize accuracy. It attempts to minimize loss. Again, there are many choices, but some form of categorical crossentropy is a good start for a classification task like this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrOAkcsD4tRc",
        "colab_type": "code",
        "outputId": "b7304c2b-6c46-432a-d3e8-55dd97e5edae",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train, epochs=3)\n",
        "val_loss, val_acc = model.evaluate(x_test, y_test)  # evaluate the out of sample data with model\n",
        "print(val_loss)  # model's loss (error)\n",
        "print(val_acc)  # model's accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2659 - acc: 0.9228\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1084 - acc: 0.9670\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0721 - acc: 0.9771\n",
            "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0874 - acc: 0.9735\n",
            "0.0873668703502044\n",
            "0.9735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvPuMxVg4tRf",
        "colab_type": "code",
        "outputId": "02f7528b-b583-4154-b846-cfdf63d965b8",
        "colab": {}
      },
      "source": [
        "model.save('epic_num_reader.model')\n",
        "new_model = tf.keras.models.load_model('epic_num_reader.model')\n",
        "predictions = new_model.predict(x_test)\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n",
            "[[6.1808532e-09 1.9234882e-08 1.7528541e-07 ... 9.9999440e-01\n",
            "  4.1788013e-09 2.8753220e-06]\n",
            " [3.0087077e-10 2.2670458e-04 9.9976641e-01 ... 7.9995868e-09\n",
            "  1.3516745e-07 6.8420812e-13]\n",
            " [8.6087304e-08 9.9979442e-01 1.8711591e-05 ... 1.6518890e-05\n",
            "  1.4055030e-04 2.1966221e-06]\n",
            " ...\n",
            " [2.6634264e-10 1.3386773e-05 4.2536804e-08 ... 6.8762056e-05\n",
            "  1.4500791e-05 5.0337080e-06]\n",
            " [1.4355449e-05 4.6657101e-07 2.3978959e-07 ... 1.2049119e-06\n",
            "  7.7280565e-03 2.9087419e-08]\n",
            " [7.0761484e-07 2.0913099e-06 3.6657732e-06 ... 1.4932031e-09\n",
            "  3.9041848e-07 2.8947906e-07]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4qIJ11N4tRi",
        "colab_type": "code",
        "outputId": "2d049643-7923-4a25-8191-e3eec4066085",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print(np.argmax(predictions[5]))\n",
        "plt.imshow(x_test[5],cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QWpb8MU4tRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}